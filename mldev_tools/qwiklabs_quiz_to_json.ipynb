{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwiklabs Quizzes to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quizzes_data():\n",
    "\n",
    "    # Load info data\n",
    "    with open('../data/gcp_courses.json') as f:\n",
    "        courses_data = json.load(f)\n",
    "\n",
    "    url = 'https://www.cloudskillsboost.google/course_sessions'\n",
    "    cookie = {'_cvl-4_1_14_session': ''}\n",
    "    quizzes_data = []\n",
    "\n",
    "    for course_data in courses_data:\n",
    "        quizzes = []\n",
    "\n",
    "        for module_data in course_data['modules']:\n",
    "            questions = []\n",
    "\n",
    "            for lesson_data in module_data['lessons']:\n",
    "                if lesson_data['type'] != 'quiz':\n",
    "                    continue\n",
    "\n",
    "                quiz_url = f\"{url}/{lesson_data['id']}\"\n",
    "                html = requests.get(quiz_url, cookies=cookie).text\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                quiz_data = json.loads(soup.find('ql-quiz')['quizversion'])\n",
    "                questions = quiz_data['quizItems']\n",
    "            \n",
    "            if questions:\n",
    "                quizzes.append({\n",
    "                    'name': module_data['name'],\n",
    "                    'questions': questions\n",
    "                })\n",
    "\n",
    "        if quizzes:\n",
    "            quizzes_data.append({\n",
    "                'name': course_data['name'],\n",
    "                'quizzes': quizzes\n",
    "            })\n",
    "            \n",
    "    # Save data\n",
    "    timestamp = datetime.datetime.now().strftime('%y%m%d')\n",
    "    file_name = f'qwiklabs_quizzes_chkp_{timestamp}.json'\n",
    "\n",
    "    with open(f'../data/{file_name}', 'w') as f:\n",
    "        f.write(json.dumps(quizzes_data, indent=2))\n",
    "\n",
    "# get_quizzes_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load quizzes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/qwiklabs_quizzes_chkp_230525.json'\n",
    "\n",
    "with open(file_path) as f:\n",
    "    quizzes_data = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing/Cleaning definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_body_start = [\n",
    "    'Choose the correct three answers.',\n",
    "    'Select the correct word below to fill in the blank:',\n",
    "    'Fill in the blank: <br>',\n",
    "    'Fill in the blanks: <br>',\n",
    "    'Fill in the blank:',\n",
    "    'Fill in the blanks.',\n",
    "    'Fill in the blank.',\n",
    "    'Fill in the blanks:'\n",
    "]\n",
    "\n",
    "remove_body_end = [\n",
    "    '(Choose 2 correct Answers)',\n",
    "    '(Choose two answers)',\n",
    "    'There could be more than one answer.',\n",
    "    'Credit is given for selecting the correct three.',\n",
    "    '(check all that apply)',\n",
    "    '<br>'\n",
    "]\n",
    "\n",
    "all_opts = 'All of the options.'\n",
    "\n",
    "replace_exp = {\n",
    "    'This answer is partially correct, please review the module again.': 'Partially correct.',\n",
    "    'This is one of the correct answers.': 'Partially correct.'\n",
    "}   \n",
    "\n",
    "remove_exp_start = [\n",
    "    'Correct Answer',\n",
    "    'Correct!',\n",
    "    'Correct.',\n",
    "    'Correct',\n",
    "    'Incorrect, please review the module',\n",
    "    'That answer is correct!',\n",
    "    'That answer is incorrect. Please review the lesson again.',\n",
    "    'This answer is correct! All three correct answers must be selected to receive credit for the question.',\n",
    "    'This answer is correct!',\n",
    "    'This answer is correct..',\n",
    "    'This answer is correct.',\n",
    "    'This answer is correct',\n",
    "    'This answer is incorrect, please review the module again.',\n",
    "    'This answer is incorrect, please review the module again',\n",
    "    'This answer is incorrect.',\n",
    "    'This answer is not correct, please review the module again.',\n",
    "    'This answer is not correct. Please review the module.',\n",
    "    'This answer is not correct. Review the module.',\n",
    "    'This answer is not correct.',\n",
    "    'This answer is not correct;',\n",
    "    'This is correct.',\n",
    "    'This is incorrect, please review the module again.',\n",
    "    'This is incorrect, please review the module again',\n",
    "    'This is one of the correct answers.',\n",
    "    'This option is correct',\n",
    "    'This option is incorrect'\n",
    "]\n",
    "\n",
    "replace_exp_end = {\n",
    "    ',” and try again.': '”.'\n",
    "}\n",
    "\n",
    "contains_exp = {\n",
    "    'Please review': 'Review'\n",
    "}\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "def preprocess_body(text):\n",
    "    for sentence in remove_body_start:\n",
    "        if text.startswith(sentence):\n",
    "            text = text[len(sentence):].lstrip()\n",
    "            break\n",
    "\n",
    "    for sentence in remove_body_end:\n",
    "        if text.endswith(sentence):\n",
    "            text = text[:-len(sentence)].rstrip()\n",
    "            break\n",
    "\n",
    "    return remove_extra_spaces(text)\n",
    "\n",
    "def preprocess_opt(text):\n",
    "    if text.startswith('All o'):\n",
    "        text = all_opts\n",
    "    else:\n",
    "        text = remove_extra_spaces(text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def preprocess_exp(exp_text):\n",
    "    exp = replace_exp.get(exp_text, exp_text)\n",
    "    text = re.sub('=+', '', exp)\n",
    "\n",
    "    for sentence in remove_exp_start:\n",
    "        if text.startswith(sentence):\n",
    "            text = text[len(sentence):].lstrip()\n",
    "            break\n",
    "\n",
    "    for sentence in replace_exp_end.keys():\n",
    "        if text.endswith(sentence):\n",
    "            text = text[:-len(sentence)] + replace_exp_end[sentence]\n",
    "\n",
    "    for k, v in contains_exp.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_item_id(resource):\n",
    "    punctuation = string.punctuation + '’'\n",
    "    item = re.sub('[%s ]+' % re.escape(punctuation), '_', resource).lower()\n",
    "\n",
    "    keywords = {\n",
    "        'introduction': 'intro',\n",
    "        'computer_vision': 'cv',\n",
    "        'convolutional_neural_networks': 'cnns',\n",
    "        'convolutional_neural_network': 'cnn',\n",
    "        'deep_neural_networks': 'dnns',\n",
    "        'deep_neural_network': 'dnn',\n",
    "        'neural_networks': 'nns',\n",
    "        'neural_network': 'nn',\n",
    "        'google_cloud': 'gcloud',\n",
    "        'bigquery': 'bq',\n",
    "        'tensorflow': 'tf',\n",
    "        'machine_learning': 'ml',\n",
    "        'natural_language_processing': 'nlp'    \n",
    "    }\n",
    "\n",
    "    for key, value in keywords.items():\n",
    "        item = item.replace(key, value)\n",
    "\n",
    "    if item.endswith('_'):\n",
    "        item = item[:-1]\n",
    "\n",
    "    return item\n",
    "\n",
    "def review_question(q):\n",
    "            \n",
    "    if q['id'] == 'how_google_does_ml_3_2':\n",
    "        for option in q['options']:\n",
    "            option['option'][0] = option['option'][0].replace('orBigQuery', 'or BigQuery')  \n",
    "\n",
    "    elif q['id'] == 'how_google_does_ml_3_3':\n",
    "        q['references'] = [\n",
    "            \"https://www.bmc.com/blogs/machine-learning-architecture/\"]\n",
    "\n",
    "    elif q['id'] == 'how_google_does_ml_4_3':\n",
    "        opt = q['options'][0]['option']\n",
    "        opt[0] = opt[0].replace('suiteof', 'suite of')\n",
    "      \n",
    "    elif q['id'] == 'tf_on_gcloud_1_6':\n",
    "        opt = q['options'][0]['option']\n",
    "        opt[0] = opt[0].replace('TensorFlowis', 'TensorFlow is')\n",
    "\n",
    "    elif q['id'] == 'tf_on_gcloud_2_7':\n",
    "        q['options'][0]['answer'] = False\n",
    "        for option in q['options']:\n",
    "            option['explanation'] = ['Partially correct.']\n",
    "\n",
    "        q['options'].append({\n",
    "            'option': [all_opts],\n",
    "            'answer': True,\n",
    "            'explanation': []\n",
    "        })\n",
    "\n",
    "        q['feedback'] = [\n",
    "            \"The original question confused adaptable layers with trainable layers.\",\n",
    "            '\"All of the options are correct.\" option was added.']\n",
    "        \n",
    "        q['references'] = [\n",
    "            'https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method']\n",
    "\n",
    "    elif q['id'] == 'tf_on_gcloud_2_8':\n",
    "        q['references'] = [\n",
    "            'https://www.tensorflow.org/guide/keras/preprocessing_layers#categorical_features_preprocessing']\n",
    "\n",
    "    elif q['id'] == 'tf_on_gcloud_4_2':\n",
    "        opt = q['options'][1]['option']\n",
    "        opt[0] = opt[0].replace('init_.py', '__init__.py')\n",
    "\n",
    "        q['references'] = [\n",
    "            'https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container']\n",
    "\n",
    "    elif q['id'] == 'tf_on_gcloud_4_3':\n",
    "        q['body'][0] = q['body'][0].replace('Verte', 'Vertex')\n",
    "\n",
    "    elif q['id'] == 'recommendation_systems_on_gcloud_2_1':\n",
    "        exp = q['options'][0]['explanation']\n",
    "        exp[0] = exp[0].replace('scaleable', 'scalable')\n",
    "\n",
    "    elif q['id'] == 'cv_fundamentals_with_gcloud_4_3':\n",
    "        q['feedback'] = [\n",
    "            \"It doesn't matter which neuron is trained to process which input values in a dense layer.\",\n",
    "            'If you randomly reshuffle the order of the pixels in the images, the classification performance stays the same, because the corresponding weights are also reshuffled.',\n",
    "            'However, when human beings look at an image where the pixels are randomly reshuffled, the image looks like noise.',\n",
    "            'This phenomenon happens because the concept of hierarchy plays a significant role in the human brain.',\n",
    "            'Information is stored in sequence of patterns, in sequential order.',\n",
    "            'Similarly, you can expect the CNNs to perform poorly in contrast to DNN models if the image pixels are randomly permitted.',\n",
    "            'This is because hierarchy, or how pixels are placed next to each other, is a vital part of the CNN model design.'\n",
    "        ]\n",
    "\n",
    "        q['references'] = [\n",
    "            'https://youtu.be/4pcqScI1jhA?t=206']\n",
    "    \n",
    "    elif q['id'] == 'feature_engineering_3_6':\n",
    "        q['body'][0] = q['body'][0].replace(\n",
    "            'tf.feature_column.bucketized_column', 'tf.keras.layers.Discretization')\n",
    "\n",
    "    elif q['id'] == 'feature_engineering_4_6':\n",
    "        opt = q['options'][1]['option']\n",
    "        opt[0] = opt[0].replace('execution.Notice', 'execution. Notice')\n",
    "\n",
    "    elif q['id'] == 'feature_engineering_6_1':\n",
    "        opt = q['options'][0]['option']\n",
    "        opt[0] = opt[0].replace('Apache', 'Apache Beam')\n",
    "\n",
    "    elif q['id'] == 'production_ml_systems_3_4':\n",
    "        q['options'][3]['explanation'] = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {}\n",
    "\n",
    "for course_data in quizzes_data:\n",
    "    course_id = get_item_id(course_data['name'])\n",
    "    questions = []\n",
    "    num_quiz = 0\n",
    "\n",
    "    for quiz in course_data['quizzes']:\n",
    "        num_quiz +=1\n",
    "\n",
    "        for i, item in enumerate(quiz['questions']):\n",
    "            q = {}\n",
    "            q['id'] = f'{course_id}_{num_quiz}_{i+1}'\n",
    "            q['domain'] = []\n",
    "            q['intro'] = []\n",
    "            q['body'] = [preprocess_body(item['stem'])]\n",
    "            q['open'] = False\n",
    "\n",
    "            options = []\n",
    "\n",
    "            for opt in item['options']:\n",
    "                exp = preprocess_exp(opt['rationale'])\n",
    "                \n",
    "                options.append({\n",
    "                    'option': [preprocess_opt(opt['title'])],\n",
    "                    'answer': opt['isAnswer'],\n",
    "                    'explanation': [exp] if exp else []\n",
    "                })\n",
    "            q['options'] = options\n",
    "\n",
    "            q['feedback'] = []\n",
    "            q['references'] = []\n",
    "            q['date'] = \"\"\n",
    "\n",
    "            review_question(q)\n",
    "\n",
    "            questions.append(q)\n",
    "                \n",
    "    processed_data[course_id] = questions\n",
    "\n",
    "formatted_data = json.dumps(processed_data, indent=2)\n",
    "formatted_data = formatted_data.replace('\\n            ', '')\n",
    "formatted_data = formatted_data.replace('\"\\n          ', '\"')\n",
    "print(formatted_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
