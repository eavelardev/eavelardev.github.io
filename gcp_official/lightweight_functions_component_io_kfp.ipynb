{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines: Lightweight Python function-based components, and component I/O"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[github](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb) - 2a25be6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, \n",
    "                        Model, Output, OutputPath, component)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define preprocess component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def preprocess(\n",
    "    message: str,\n",
    "    output_dataset_one: Output[Dataset],\n",
    "    output_dataset_two_path: OutputPath(\"Dataset\"),\n",
    "    output_parameter_path: OutputPath(str)\n",
    "):\n",
    "    output_dataset_one.metadata[\"hello\"] = \"there\",\n",
    "\n",
    "    with open(output_dataset_one.path, \"w\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "    with open(output_dataset_two_path, \"w\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "    with open(output_parameter_path, \"w\") as f:\n",
    "        f.write(message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def train(\n",
    "    message: str,\n",
    "    dataset_one_path: InputPath(\"Dataset\"),\n",
    "    dataset_two: Input[Dataset],\n",
    "    imported_dataset: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "    num_steps: int = 3\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"output_message\", str),\n",
    "        (\"generic_artifact\", Artifact)\n",
    "    ]\n",
    "):\n",
    "    with open(dataset_one_path) as f:\n",
    "        dataset_one_contents = f.read()\n",
    "\n",
    "    with open(dataset_two.path) as f:\n",
    "        dataset_two_contents = f.read()\n",
    "\n",
    "    with open(model.path, \"w\") as f:\n",
    "        f.write(\"My Model\")\n",
    "\n",
    "    with open(imported_dataset.path) as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    print(\"Imported Dataset:\", data)\n",
    "\n",
    "    model.metadata[\"accuracy\"] = 0.9\n",
    "    model.metadata[\"framework\"] = \"Tensorflow\"\n",
    "    model.metadata[\"time_to_train_in_seconds\"] = 257\n",
    "\n",
    "    artifact_contents = f\"{dataset_one_contents}\\n{dataset_two_contents}\"\n",
    "    output_message = \" \".join([message for _ in range(num_steps)])\n",
    "    return (output_message, artifact_contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define read artifact input component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def read_artifact_input(\n",
    "    generic: Input[Artifact]\n",
    "):\n",
    "    with open(generic.path) as f:\n",
    "        generic_contents = f.read()\n",
    "        print(f\"generic contents: {generic_contents}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"metadata-pipeline-v2\")\n",
    "def pipeline(message: str):\n",
    "    importer = kfp.dsl.importer(\n",
    "        artifact_uri=\"gs://ml-pipeline-playground/shakespeare1.txt\",\n",
    "        artifact_class=Dataset,\n",
    "        reimport=False\n",
    "    )\n",
    "    preprocess_task = preprocess(message=message)\n",
    "    train_task = train(\n",
    "        dataset_one_path=preprocess_task.outputs[\"output_dataset_one\"],\n",
    "        dataset_two=preprocess_task.outputs[\"output_dataset_two_path\"],\n",
    "        imported_dataset=importer.output,\n",
    "        message=preprocess_task.outputs[\"output_parameter_path\"],\n",
    "        num_steps=5\n",
    "    )\n",
    "    read_task = read_artifact_input(generic=train_task.outputs[\"generic_artifact\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = 'lightweight-pipeline.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(pipeline_func=pipeline, \n",
    "                                   package_path=pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dsl.importer is not supported with v1 compiler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kfp\u001b[39m.\u001b[39;49mcompiler\u001b[39m.\u001b[39;49mCompiler(\n\u001b[1;32m      2\u001b[0m     mode\u001b[39m=\u001b[39;49mkfp\u001b[39m.\u001b[39;49mdsl\u001b[39m.\u001b[39;49mPipelineExecutionMode\u001b[39m.\u001b[39;49mV2_COMPATIBLE)\u001b[39m.\u001b[39;49mcompile(\n\u001b[1;32m      3\u001b[0m         pipeline_func\u001b[39m=\u001b[39;49mpipeline, \n\u001b[1;32m      4\u001b[0m         package_path\u001b[39m=\u001b[39;49mpipeline_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/compiler/compiler.py:1175\u001b[0m, in \u001b[0;36mCompiler.compile\u001b[0;34m(self, pipeline_func, package_path, type_check, pipeline_conf)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1174\u001b[0m     kfp\u001b[39m.\u001b[39mTYPE_CHECK \u001b[39m=\u001b[39m type_check\n\u001b[0;32m-> 1175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_and_write_workflow(\n\u001b[1;32m   1176\u001b[0m         pipeline_func\u001b[39m=\u001b[39;49mpipeline_func,\n\u001b[1;32m   1177\u001b[0m         pipeline_conf\u001b[39m=\u001b[39;49mpipeline_conf,\n\u001b[1;32m   1178\u001b[0m         package_path\u001b[39m=\u001b[39;49mpackage_path)\n\u001b[1;32m   1179\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1180\u001b[0m     kfp\u001b[39m.\u001b[39mTYPE_CHECK \u001b[39m=\u001b[39m type_check_old_value\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/compiler/compiler.py:1227\u001b[0m, in \u001b[0;36mCompiler._create_and_write_workflow\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf, package_path)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_and_write_workflow\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   1219\u001b[0m                                pipeline_func: Callable,\n\u001b[1;32m   1220\u001b[0m                                pipeline_name: Text \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1223\u001b[0m                                pipeline_conf: dsl\u001b[39m.\u001b[39mPipelineConf \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1224\u001b[0m                                package_path: Text \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compile the given pipeline function and dump it to specified file\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[39m    format.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m     workflow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_workflow(pipeline_func, pipeline_name,\n\u001b[1;32m   1228\u001b[0m                                      pipeline_description, params_list,\n\u001b[1;32m   1229\u001b[0m                                      pipeline_conf)\n\u001b[1;32m   1230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_workflow(workflow, package_path)\n\u001b[1;32m   1231\u001b[0m     _validate_workflow(workflow)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/compiler/compiler.py:1058\u001b[0m, in \u001b[0;36mCompiler._create_workflow\u001b[0;34m(self, pipeline_func, pipeline_name, pipeline_description, params_list, pipeline_conf)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[39mif\u001b[39;00m insert_pipeline_root_param:\n\u001b[1;32m   1056\u001b[0m             op\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_root_param)\n\u001b[0;32m-> 1058\u001b[0m workflow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_pipeline_workflow(\n\u001b[1;32m   1059\u001b[0m     args_list_with_defaults,\n\u001b[1;32m   1060\u001b[0m     dsl_pipeline,\n\u001b[1;32m   1061\u001b[0m     op_transformers,\n\u001b[1;32m   1062\u001b[0m     pipeline_conf,\n\u001b[1;32m   1063\u001b[0m )\n\u001b[1;32m   1065\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_data_passing_rewriter\u001b[39;00m \u001b[39mimport\u001b[39;00m fix_big_data_passing\n\u001b[1;32m   1066\u001b[0m workflow \u001b[39m=\u001b[39m fix_big_data_passing(workflow)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/compiler/compiler.py:786\u001b[0m, in \u001b[0;36mCompiler._create_pipeline_workflow\u001b[0;34m(self, parameter_defaults, pipeline, op_transformers, pipeline_conf)\u001b[0m\n\u001b[1;32m    783\u001b[0m pipeline_group\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m temp_pipeline_group_name\n\u001b[1;32m    785\u001b[0m \u001b[39m# Templates\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m templates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dag_templates(pipeline, op_transformers)\n\u001b[1;32m    788\u001b[0m \u001b[39m# Exit Handler\u001b[39;00m\n\u001b[1;32m    789\u001b[0m exit_handler \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/compiler/compiler.py:746\u001b[0m, in \u001b[0;36mCompiler._create_dag_templates\u001b[0;34m(self, pipeline, op_transformers, op_to_templates_handler)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m pipeline\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    745\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(op, \u001b[39m'\u001b[39m\u001b[39mimporter_spec\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 746\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    747\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mdsl.importer is not supported with v1 compiler.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    748\u001b[0m         )\n\u001b[1;32m    750\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m dsl\u001b[39m.\u001b[39mPipelineExecutionMode\u001b[39m.\u001b[39mV2_COMPATIBLE:\n\u001b[1;32m    751\u001b[0m         v2_compat\u001b[39m.\u001b[39mupdate_op(\n\u001b[1;32m    752\u001b[0m             op,\n\u001b[1;32m    753\u001b[0m             pipeline_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_name_param,\n\u001b[1;32m    754\u001b[0m             pipeline_root\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_root_param,\n\u001b[1;32m    755\u001b[0m             launcher_image\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launcher_image)\n",
      "\u001b[0;31mValueError\u001b[0m: dsl.importer is not supported with v1 compiler."
     ]
    }
   ],
   "source": [
    "kfp.compiler.Compiler(\n",
    "    mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE).compile(\n",
    "        pipeline_func=pipeline, \n",
    "        package_path=pipeline_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_endpoint = \"http://localhost:8080/pipeline\"\n",
    "\n",
    "kfp.Client(host=kfp_endpoint).create_run_from_pipeline_func(\n",
    "    pipeline_file,\n",
    "    arguments={\"message\": \"Hello, World\"},\n",
    "    mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "    enable_caching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/pipeline/#/experiments/details/8faa75b7-6169-4baa-b5c9-bd92f9c0f365\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The package_file lightweight-pipeline.json should end with one of the following formats: [.tar.gz, .tgz, .zip, .yaml, .yml]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m kfp_endpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttp://localhost:8080/pipeline\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m kfp\u001b[39m.\u001b[39;49mClient(host\u001b[39m=\u001b[39;49mkfp_endpoint)\u001b[39m.\u001b[39;49mcreate_run_from_pipeline_package(\n\u001b[1;32m      4\u001b[0m     pipeline_file,\n\u001b[1;32m      5\u001b[0m     arguments\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mHello, World\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m      6\u001b[0m     \u001b[39m# mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     enable_caching\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/_client.py:1081\u001b[0m, in \u001b[0;36mClient.create_run_from_pipeline_package\u001b[0;34m(self, pipeline_file, arguments, run_name, experiment_name, namespace, pipeline_root, enable_caching, service_account)\u001b[0m\n\u001b[1;32m   1076\u001b[0m run_name \u001b[39m=\u001b[39m run_name \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   1077\u001b[0m     pipeline_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m   1078\u001b[0m     datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1079\u001b[0m experiment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_experiment(\n\u001b[1;32m   1080\u001b[0m     name\u001b[39m=\u001b[39mexperiment_name, namespace\u001b[39m=\u001b[39mnamespace)\n\u001b[0;32m-> 1081\u001b[0m run_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_pipeline(\n\u001b[1;32m   1082\u001b[0m     experiment_id\u001b[39m=\u001b[39;49mexperiment\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m   1083\u001b[0m     job_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m   1084\u001b[0m     pipeline_package_path\u001b[39m=\u001b[39;49mpipeline_file,\n\u001b[1;32m   1085\u001b[0m     params\u001b[39m=\u001b[39;49marguments,\n\u001b[1;32m   1086\u001b[0m     pipeline_root\u001b[39m=\u001b[39;49mpipeline_root,\n\u001b[1;32m   1087\u001b[0m     enable_caching\u001b[39m=\u001b[39;49menable_caching,\n\u001b[1;32m   1088\u001b[0m     service_account\u001b[39m=\u001b[39;49mservice_account,\n\u001b[1;32m   1089\u001b[0m )\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m RunPipelineResult(\u001b[39mself\u001b[39m, run_info)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/_client.py:737\u001b[0m, in \u001b[0;36mClient.run_pipeline\u001b[0;34m(self, experiment_id, job_name, pipeline_package_path, params, pipeline_id, version_id, pipeline_root, enable_caching, service_account)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[39mif\u001b[39;00m pipeline_root \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     params[dsl\u001b[39m.\u001b[39mROOT_PARAMETER_NAME] \u001b[39m=\u001b[39m pipeline_root\n\u001b[0;32m--> 737\u001b[0m job_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_job_config(\n\u001b[1;32m    738\u001b[0m     experiment_id\u001b[39m=\u001b[39;49mexperiment_id,\n\u001b[1;32m    739\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    740\u001b[0m     pipeline_package_path\u001b[39m=\u001b[39;49mpipeline_package_path,\n\u001b[1;32m    741\u001b[0m     pipeline_id\u001b[39m=\u001b[39;49mpipeline_id,\n\u001b[1;32m    742\u001b[0m     version_id\u001b[39m=\u001b[39;49mversion_id,\n\u001b[1;32m    743\u001b[0m     enable_caching\u001b[39m=\u001b[39;49menable_caching,\n\u001b[1;32m    744\u001b[0m )\n\u001b[1;32m    745\u001b[0m run_body \u001b[39m=\u001b[39m kfp_server_api\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mApiRun(\n\u001b[1;32m    746\u001b[0m     pipeline_spec\u001b[39m=\u001b[39mjob_config\u001b[39m.\u001b[39mspec,\n\u001b[1;32m    747\u001b[0m     resource_references\u001b[39m=\u001b[39mjob_config\u001b[39m.\u001b[39mresource_references,\n\u001b[1;32m    748\u001b[0m     name\u001b[39m=\u001b[39mjob_name,\n\u001b[1;32m    749\u001b[0m     service_account\u001b[39m=\u001b[39mservice_account)\n\u001b[1;32m    751\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_api\u001b[39m.\u001b[39mcreate_run(body\u001b[39m=\u001b[39mrun_body)\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/_client.py:901\u001b[0m, in \u001b[0;36mClient._create_job_config\u001b[0;34m(self, experiment_id, params, pipeline_package_path, pipeline_id, version_id, enable_caching)\u001b[0m\n\u001b[1;32m    899\u001b[0m pipeline_json_string \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39mif\u001b[39;00m pipeline_package_path:\n\u001b[0;32m--> 901\u001b[0m     pipeline_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_pipeline_yaml(pipeline_package_path)\n\u001b[1;32m    903\u001b[0m     \u001b[39m# Caching option set at submission time overrides the compile time settings.\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m enable_caching \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mldev/lib/python3.9/site-packages/kfp/_client.py:652\u001b[0m, in \u001b[0;36mClient._extract_pipeline_yaml\u001b[0;34m(self, package_file)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[39mreturn\u001b[39;00m yaml\u001b[39m.\u001b[39msafe_load(f)\n\u001b[1;32m    651\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 652\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    653\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe package_file \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m package_file \u001b[39m+\u001b[39m\n\u001b[1;32m    654\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m should end with one of the following formats: [.tar.gz, .tgz, .zip, .yaml, .yml]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    655\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The package_file lightweight-pipeline.json should end with one of the following formats: [.tar.gz, .tgz, .zip, .yaml, .yml]"
     ]
    }
   ],
   "source": [
    "kfp_endpoint = \"http://localhost:8080/pipeline\"\n",
    "\n",
    "kfp.Client(host=kfp_endpoint).create_run_from_pipeline_package(\n",
    "    pipeline_file,\n",
    "    arguments={\"message\": \"Hello, World\"},\n",
    "    # mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "    enable_caching=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
